{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9c7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import silhouette_score\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "# пути и параметры\n",
    "\n",
    "paths = {\n",
    "    \"drones\": \"../data/drones\",\n",
    "    \"not_drones\": \"../data/not_drones\"\n",
    "}\n",
    "\n",
    "SAVE_DIR = \"../embeddings\"\n",
    "SAVE_PATH = os.path.join(SAVE_DIR, \"vggish.npz\")\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0262cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дронов: 1411\n",
      "не дронов: 1304\n",
      "всего: 2715\n"
     ]
    }
   ],
   "source": [
    "# функция сбора файлов\n",
    "\n",
    "def collect_files(path):\n",
    "    out = []\n",
    "    for root, _, fs in os.walk(path):\n",
    "        for f in fs:\n",
    "            if f.lower().endswith((\".wav\", \".mp3\")):\n",
    "                out.append(os.path.join(root, f))\n",
    "    return sorted(out)\n",
    "\n",
    "\n",
    "\n",
    "# собираем 50% файлов\n",
    "\n",
    "drones_all = collect_files(paths[\"drones\"])\n",
    "not_drones_all = collect_files(paths[\"not_drones\"])\n",
    "\n",
    "drones_sel = drones_all[: len(drones_all) // 50]\n",
    "not_drones_sel = not_drones_all[: len(not_drones_all) // 50]\n",
    "\n",
    "files = drones_sel + not_drones_sel\n",
    "labels = [1] * len(drones_sel) + [0] * len(not_drones_sel)\n",
    "\n",
    "print(\"дронов:\", len(drones_sel))\n",
    "print(\"не дронов:\", len(not_drones_sel))\n",
    "print(\"всего:\", len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca56fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "загрузка...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "аудио: 100%|██████████| 2715/2715 [00:03<00:00, 717.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "загружено: 2715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# загрузка аудио\n",
    "\n",
    "def load_audio(path):\n",
    "    try:\n",
    "        audio, sr = librosa.load(path, sr=None, mono=True)\n",
    "        return path, audio, sr\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"загрузка...\")\n",
    "loaded = []\n",
    "with ThreadPoolExecutor(max_workers=8) as ex:\n",
    "    for item in tqdm(ex.map(load_audio, files), total=len(files), desc=\"аудио\"):\n",
    "        if item is not None:\n",
    "            loaded.append(item)\n",
    "\n",
    "print(\"загружено:\", len(loaded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f51ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "модель...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Samat/.cache\\torch\\hub\\harritaylor_torchvggish_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# загрузка VGGish\n",
    "print(\"модель...\")\n",
    "model = torch.hub.load('harritaylor/torchvggish', 'vggish')\n",
    "model.eval()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f614df50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "эмбеддинги...\n",
      "обработано: 100\n",
      "обработано: 200\n",
      "обработано: 300\n",
      "обработано: 400\n",
      "обработано: 500\n",
      "обработано: 600\n",
      "обработано: 700\n",
      "обработано: 800\n",
      "обработано: 900\n",
      "обработано: 1000\n",
      "обработано: 1100\n",
      "эмбеддингов: 1122\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# эмбеддинги\n",
    "# --------------------------\n",
    "print(\"эмбеддинги...\")\n",
    "embeddings = []\n",
    "processed = 0\n",
    "\n",
    "for path, audio, sr in loaded:\n",
    "\n",
    "    # vggish требует 16k\n",
    "    if sr != 16000:\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
    "\n",
    "    audio = audio.astype(np.float32)\n",
    "\n",
    "    # минимум 1 секунда\n",
    "    if len(audio) < 16000:\n",
    "        audio = np.pad(audio, (0, 16000 - len(audio)), mode=\"constant\")\n",
    "\n",
    "    emb = None\n",
    "\n",
    "    # пробуем подать numpy → vggish\n",
    "    try:\n",
    "        out = model.forward(audio)\n",
    "        if out is not None and len(out) > 0:\n",
    "            emb = out\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # если numpy не сработал → пробуем путь\n",
    "    if emb is None:\n",
    "        try:\n",
    "            out = model.forward(path)\n",
    "            if out is not None and len(out) > 0:\n",
    "                emb = out\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if emb is None:\n",
    "        continue\n",
    "\n",
    "    # усредняем\n",
    "    e = emb.mean(axis=0)\n",
    "\n",
    "    # приводим тензор → numpy\n",
    "    if isinstance(e, torch.Tensor):\n",
    "        e = e.detach().cpu().numpy()\n",
    "\n",
    "    # проверяем форму\n",
    "    if e.shape != (128,):\n",
    "        continue\n",
    "\n",
    "    embeddings.append(e)\n",
    "    processed += 1\n",
    "\n",
    "    if processed % 100 == 0:\n",
    "        print(\"обработано:\", processed)\n",
    "\n",
    "print(\"эмбеддингов:\", len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6edb473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1122, 128)\n",
      "y: (1122,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# silhouette\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msil:\u001b[39m\u001b[38;5;124m\"\u001b[39m, score)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# сохранение\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Samat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Samat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:138\u001b[0m, in \u001b[0;36msilhouette_score\u001b[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(silhouette_samples(X, labels, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)))\n",
      "File \u001b[1;32mc:\\Users\\Samat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Samat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:296\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[1;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[0;32m    294\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[0;32m    295\u001b[0m label_freqs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(labels)\n\u001b[1;32m--> 296\u001b[0m \u001b[43mcheck_number_of_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[0;32m    299\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    300\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[0;32m    301\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Samat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:35\u001b[0m, in \u001b[0;36mcheck_number_of_labels\u001b[1;34m(n_labels, n_samples)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    Number of samples.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m n_labels \u001b[38;5;241m<\u001b[39m n_samples:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. Valid values are 2 to n_samples - 1 (inclusive)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;241m%\u001b[39m n_labels\n\u001b[0;32m     38\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# формируем X, y\n",
    "# --------------------------\n",
    "if len(embeddings) == 0:\n",
    "    print(\"нет эмбеддингов — ошибка\")\n",
    "    raise SystemExit\n",
    "\n",
    "X = np.vstack(embeddings)\n",
    "y = np.array(labels[:len(X)])\n",
    "\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "\n",
    "# --------------------------\n",
    "# silhouette\n",
    "# --------------------------\n",
    "score = silhouette_score(X, y)\n",
    "print(\"sil:\", score)\n",
    "\n",
    "# --------------------------\n",
    "# сохранение\n",
    "# --------------------------\n",
    "np.savez(SAVE_PATH, X=X, y=y, score=score)\n",
    "print(\"сохранено:\", SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
