{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c3a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import torch\n",
    "\n",
    "# ===== настройки =====\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "paths = {\n",
    "    \"drones\": \"../data/drones\",\n",
    "    \"not_drones\": \"../data/not_drones\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9c46206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "дронов: 1411\n",
      "не дронов: 1304\n",
      "всего: 2715\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "BEATS_DIR = \"./beats\"   # путь к скачанной папке\n",
    "BEATS_DIR = os.path.abspath(BEATS_DIR)\n",
    "sys.path.append(BEATS_DIR)\n",
    "\n",
    "from BEATs import BEATs, BEATsConfig\n",
    "\n",
    "# путь до чекпойнта модели (.pt), скачанного из релизов BEATs\n",
    "# пример: \"BEATs_iter3_plus_AS2M.pt\" или \"BEATs_iter3.pt\"\n",
    "MODEL_PATH = os.path.join(BEATS_DIR, \"BEATs_iter3.pt\")  # <<< ПОМЕНЯЙ НА СВОЙ ФАЙЛ\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ===== файлы =====\n",
    "\n",
    "def collect_files(path):\n",
    "    fs = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if f.lower().endswith((\".wav\", \".mp3\")):\n",
    "                fs.append(os.path.join(root, f))\n",
    "    return sorted(fs)\n",
    "\n",
    "drones_all = collect_files(paths[\"drones\"])\n",
    "not_drones_all = collect_files(paths[\"not_drones\"])\n",
    "\n",
    "# берем часть (1/50)\n",
    "drones_sel = drones_all[: len(drones_all) // 50]\n",
    "not_drones_sel = not_drones_all[: len(not_drones_all) // 50]\n",
    "\n",
    "files = drones_sel + not_drones_sel\n",
    "labels = [1] * len(drones_sel) + [0] * len(not_drones_sel)\n",
    "\n",
    "print(\"дронов:\", len(drones_sel))\n",
    "print(\"не дронов:\", len(not_drones_sel))\n",
    "print(\"всего:\", len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654a571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "модель...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "загрузка...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "аудио: 100%|██████████| 2715/2715 [00:05<00:00, 487.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "загружено: 2715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== модель beats =====\n",
    "\n",
    "print(\"модель...\")\n",
    "\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "cfg = BEATsConfig(checkpoint[\"cfg\"])\n",
    "beats_model = BEATs(cfg)\n",
    "beats_model.load_state_dict(checkpoint[\"model\"])\n",
    "beats_model.to(device)\n",
    "beats_model.eval()\n",
    "\n",
    "print(\"ok\")\n",
    "\n",
    "# ===== загрузка аудио =====\n",
    "\n",
    "def load_audio(path):\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    try:\n",
    "        audio, sr = librosa.load(path, sr=None, mono=True)\n",
    "        return audio, sr\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "print(\"загрузка...\")\n",
    "loaded = []\n",
    "with ThreadPoolExecutor(max_workers=8) as ex:\n",
    "    for item in tqdm(ex.map(load_audio, files), total=len(files), desc=\"аудио\"):\n",
    "        if item is not None:\n",
    "            loaded.append(item)\n",
    "\n",
    "print(\"загружено:\", len(loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "126329d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "эмбеддинги...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samat\\AppData\\Local\\Temp\\ipykernel_9328\\1085348468.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  audio_tensor = torch.tensor(waves_pad, dtype=torch.float32, device=device)  # (b, t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "обработано: 100\n",
      "обработано: 200\n",
      "обработано: 300\n",
      "обработано: 400\n",
      "обработано: 500\n",
      "обработано: 600\n",
      "обработано: 700\n",
      "обработано: 800\n",
      "обработано: 900\n",
      "обработано: 1000\n",
      "обработано: 1100\n",
      "обработано: 1200\n",
      "обработано: 1300\n",
      "обработано: 1400\n",
      "обработано: 1500\n",
      "обработано: 1600\n",
      "обработано: 1700\n",
      "обработано: 1800\n",
      "обработано: 1900\n",
      "обработано: 2000\n",
      "обработано: 2100\n",
      "обработано: 2200\n",
      "обработано: 2300\n",
      "обработано: 2400\n",
      "обработано: 2500\n",
      "обработано: 2600\n",
      "обработано: 2700\n",
      "эмбеддингов: 2715\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== эмбеддинги beats =====\n",
    "\n",
    "print(\"эмбеддинги...\")\n",
    "embeddings = []\n",
    "batch_size = 4\n",
    "processed = 0\n",
    "\n",
    "for i in range(0, len(loaded), batch_size):\n",
    "    batch = loaded[i:i + batch_size]\n",
    "    if not batch:\n",
    "        continue\n",
    "\n",
    "    # ресемпл до 16к\n",
    "    waves = []\n",
    "    for audio, sr in batch:\n",
    "        if sr != 16000:\n",
    "            audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
    "        waves.append(audio)\n",
    "\n",
    "    # выравнивание длины\n",
    "    max_len = max(len(w) for w in waves)\n",
    "    waves_pad = [librosa.util.fix_length(w, size=max_len) for w in waves]\n",
    "\n",
    "    audio_tensor = torch.tensor(waves_pad, dtype=torch.float32, device=device)  # (b, t)\n",
    "    padding_mask = torch.zeros(audio_tensor.shape, dtype=torch.bool, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        rep = beats_model.extract_features(audio_tensor, padding_mask=padding_mask)[0]\n",
    "        # rep: (b, t, dim) или (b, dim) в зав-ти от версии\n",
    "        if rep.dim() == 3:\n",
    "            rep_pooled = rep.mean(dim=1)  # (b, dim)\n",
    "        else:\n",
    "            rep_pooled = rep  # (b, dim)\n",
    "\n",
    "    for vec in rep_pooled.cpu().numpy():\n",
    "        embeddings.append(vec)\n",
    "        processed += 1\n",
    "        if processed % 100 == 0:\n",
    "            print(\"обработано:\", processed)\n",
    "\n",
    "print(\"эмбеддингов:\", len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1cdd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X форма: (2715, 768)\n",
      "y форма: (2715,)\n",
      "sil: 0.46975770592689514\n",
      "сохранено: ../embeddings/beats.npz\n"
     ]
    }
   ],
   "source": [
    "if len(embeddings) == 0:\n",
    "    print(\"нет эмбеддингов — ошибка\")\n",
    "    raise SystemExit()\n",
    "\n",
    "# ===== массивы =====\n",
    "\n",
    "X = np.vstack(embeddings)\n",
    "y = np.array(labels[: len(X)])\n",
    "\n",
    "print(\"X форма:\", X.shape)\n",
    "print(\"y форма:\", y.shape)\n",
    "\n",
    "# ===== метрика =====\n",
    "\n",
    "score = silhouette_score(X, y)\n",
    "print(\"sil:\", score)\n",
    "\n",
    "# ===== сохранение =====\n",
    "\n",
    "os.makedirs(\"../embeddings\", exist_ok=True)\n",
    "save_path = \"../embeddings/beats.npz\"\n",
    "np.savez(save_path, X=X, y=y, score=score)\n",
    "\n",
    "print(\"сохранено:\", save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
